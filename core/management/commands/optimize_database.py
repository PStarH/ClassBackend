"""
æ•°æ®åº“ä¼˜åŒ–ç®¡ç†å‘½ä»¤
åº”ç”¨ç´¢å¼•ä¼˜åŒ–ã€è¿æ¥æ± é…ç½®å’Œæ€§èƒ½è°ƒä¼˜
"""
from django.core.management.base import BaseCommand
from django.db import connection, transaction
from django.conf import settings
import logging
import time

from core.performance.advanced_database_config import (
    create_indexes_sql,
    optimize_database_settings,
    DatabaseHealthChecker,
    INDEX_OPTIMIZATION_CONFIG
)

logger = logging.getLogger(__name__)

class Command(BaseCommand):
    help = 'Optimize database with indexes, connection pool and performance tuning'

    def add_arguments(self, parser):
        parser.add_argument(
            '--create-indexes',
            action='store_true',
            help='Create optimized indexes for high frequency queries',
        )
        parser.add_argument(
            '--optimize-settings',
            action='store_true',
            help='Apply PostgreSQL performance settings',
        )
        parser.add_argument(
            '--health-check',
            action='store_true',
            help='Run database health checks',
        )
        parser.add_argument(
            '--analyze-tables',
            action='store_true',
            help='Update table statistics for query optimizer',
        )
        parser.add_argument(
            '--vacuum-analyze',
            action='store_true',
            help='Run VACUUM ANALYZE on all tables',
        )
        parser.add_argument(
            '--dry-run',
            action='store_true',
            help='Show what would be done without executing',
        )

    def handle(self, *args, **options):
        self.stdout.write(
            self.style.SUCCESS('ğŸš€ Starting database optimization...')
        )

        if options['health_check']:
            self.run_health_checks()

        if options['create_indexes']:
            self.create_optimized_indexes(dry_run=options['dry_run'])

        if options['optimize_settings']:
            self.apply_performance_settings(dry_run=options['dry_run'])

        if options['analyze_tables']:
            self.analyze_tables(dry_run=options['dry_run'])

        if options['vacuum_analyze']:
            self.vacuum_analyze_tables(dry_run=options['dry_run'])

        self.stdout.write(
            self.style.SUCCESS('âœ… Database optimization completed!')
        )

    def run_health_checks(self):
        """è¿è¡Œæ•°æ®åº“å¥åº·æ£€æŸ¥"""
        self.stdout.write(
            self.style.WARNING('ğŸ“Š Running database health checks...')
        )

        # è¿æ¥æ± æ£€æŸ¥
        pool_status = DatabaseHealthChecker.check_connection_pool()
        if pool_status['status'] == 'ok':
            self.stdout.write(
                self.style.SUCCESS(
                    f"âœ… Connection pool: {pool_status['active_connections']}/{pool_status['max_connections']} "
                    f"({pool_status['usage_ratio']:.1%})"
                )
            )
        else:
            self.stdout.write(
                self.style.ERROR(
                    f"âŒ Connection pool issue: {pool_status.get('error', 'High usage')}"
                )
            )

        # æ…¢æŸ¥è¯¢æ£€æŸ¥
        slow_queries = DatabaseHealthChecker.check_slow_queries()
        if slow_queries['status'] == 'ok':
            self.stdout.write(
                self.style.SUCCESS("âœ… No slow queries detected")
            )
        else:
            self.stdout.write(
                self.style.WARNING(
                    f"âš ï¸  Found {len(slow_queries.get('slow_queries', []))} slow queries"
                )
            )

        # æ•°æ®åº“å¤§å°æ£€æŸ¥
        self.check_database_size()

        # ç´¢å¼•ä½¿ç”¨æƒ…å†µæ£€æŸ¥
        self.check_index_usage()

    def check_database_size(self):
        """æ£€æŸ¥æ•°æ®åº“å¤§å°"""
        try:
            with connection.cursor() as cursor:
                cursor.execute("""
                    SELECT 
                        pg_size_pretty(pg_database_size(current_database())) as db_size,
                        (SELECT count(*) FROM pg_stat_activity WHERE state = 'active') as active_connections
                """)
                result = cursor.fetchone()
                self.stdout.write(
                    self.style.SUCCESS(
                        f"ğŸ’¾ Database size: {result[0]}, Active connections: {result[1]}"
                    )
                )
        except Exception as e:
            self.stdout.write(
                self.style.ERROR(f"âŒ Size check failed: {e}")
            )

    def check_index_usage(self):
        """æ£€æŸ¥ç´¢å¼•ä½¿ç”¨æƒ…å†µ"""
        try:
            with connection.cursor() as cursor:
                cursor.execute("""
                    SELECT 
                        schemaname,
                        tablename,
                        indexname,
                        idx_tup_read,
                        idx_tup_fetch
                    FROM pg_stat_user_indexes 
                    WHERE idx_tup_read = 0 OR idx_tup_fetch = 0
                    ORDER BY schemaname, tablename;
                """)
                unused_indexes = cursor.fetchall()
                
                if unused_indexes:
                    self.stdout.write(
                        self.style.WARNING(
                            f"âš ï¸  Found {len(unused_indexes)} potentially unused indexes"
                        )
                    )
                    for idx in unused_indexes:
                        self.stdout.write(f"  - {idx[0]}.{idx[1]}.{idx[2]}")
                else:
                    self.stdout.write(
                        self.style.SUCCESS("âœ… All indexes are being used")
                    )
        except Exception as e:
            self.stdout.write(
                self.style.ERROR(f"âŒ Index usage check failed: {e}")
            )

    def create_optimized_indexes(self, dry_run=False):
        """åˆ›å»ºä¼˜åŒ–ç´¢å¼•"""
        self.stdout.write(
            self.style.WARNING('ğŸ”§ Creating optimized indexes...')
        )

        sql_statements = create_indexes_sql()
        
        if dry_run:
            self.stdout.write(
                self.style.WARNING("ğŸ“‹ DRY RUN - Would execute the following SQL:")
            )
            for sql in sql_statements:
                self.stdout.write(f"  {sql}")
            return

        success_count = 0
        total_count = len(sql_statements)

        for sql in sql_statements:
            try:
                start_time = time.time()
                with connection.cursor() as cursor:
                    cursor.execute(sql)
                
                execution_time = time.time() - start_time
                self.stdout.write(
                    self.style.SUCCESS(
                        f"âœ… Index created in {execution_time:.2f}s: {sql[:80]}..."
                    )
                )
                success_count += 1
                
            except Exception as e:
                if "already exists" in str(e):
                    self.stdout.write(
                        self.style.WARNING(f"âš ï¸  Index already exists: {sql[:80]}...")
                    )
                    success_count += 1
                else:
                    self.stdout.write(
                        self.style.ERROR(f"âŒ Failed to create index: {e}")
                    )

        self.stdout.write(
            self.style.SUCCESS(
                f"ğŸ“Š Index creation summary: {success_count}/{total_count} successful"
            )
        )

    def apply_performance_settings(self, dry_run=False):
        """åº”ç”¨æ€§èƒ½è®¾ç½®"""
        self.stdout.write(
            self.style.WARNING('âš™ï¸  Applying performance settings...')
        )

        settings_dict = optimize_database_settings()
        
        if dry_run:
            self.stdout.write(
                self.style.WARNING("ğŸ“‹ DRY RUN - Would apply the following settings:")
            )
            for key, value in settings_dict.items():
                self.stdout.write(f"  {key} = {value}")
            return

        # æ³¨æ„ï¼šè¿™äº›è®¾ç½®éœ€è¦æ•°æ®åº“ç®¡ç†å‘˜æƒé™ï¼Œé€šå¸¸åœ¨postgresql.confä¸­é…ç½®
        self.stdout.write(
            self.style.WARNING(
                "âš ï¸  Performance settings require database admin privileges.\n"
                "   Please apply these settings in postgresql.conf:"
            )
        )
        
        for key, value in settings_dict.items():
            self.stdout.write(f"  {key} = {value}")

        # åº”ç”¨ä¸€äº›å¯ä»¥åœ¨ä¼šè¯çº§åˆ«è®¾ç½®çš„å‚æ•°
        session_settings = [
            "SET statement_timeout = '30s'",
            "SET lock_timeout = '5s'", 
            "SET idle_in_transaction_session_timeout = '10min'",
        ]

        for setting in session_settings:
            try:
                with connection.cursor() as cursor:
                    cursor.execute(setting)
                self.stdout.write(
                    self.style.SUCCESS(f"âœ… Applied: {setting}")
                )
            except Exception as e:
                self.stdout.write(
                    self.style.ERROR(f"âŒ Failed to apply {setting}: {e}")
                )

    def analyze_tables(self, dry_run=False):
        """æ›´æ–°è¡¨ç»Ÿè®¡ä¿¡æ¯"""
        self.stdout.write(
            self.style.WARNING('ğŸ“ˆ Updating table statistics...')
        )

        if dry_run:
            self.stdout.write(
                self.style.WARNING("ğŸ“‹ DRY RUN - Would run ANALYZE on all tables")
            )
            return

        try:
            start_time = time.time()
            with connection.cursor() as cursor:
                cursor.execute("ANALYZE;")
            
            execution_time = time.time() - start_time
            self.stdout.write(
                self.style.SUCCESS(
                    f"âœ… ANALYZE completed in {execution_time:.2f}s"
                )
            )
        except Exception as e:
            self.stdout.write(
                self.style.ERROR(f"âŒ ANALYZE failed: {e}")
            )

    def vacuum_analyze_tables(self, dry_run=False):
        """è¿è¡ŒVACUUM ANALYZE"""
        self.stdout.write(
            self.style.WARNING('ğŸ§¹ Running VACUUM ANALYZE...')
        )

        if dry_run:
            self.stdout.write(
                self.style.WARNING("ğŸ“‹ DRY RUN - Would run VACUUM ANALYZE")
            )
            return

        # è·å–æ‰€æœ‰ç”¨æˆ·è¡¨
        try:
            with connection.cursor() as cursor:
                cursor.execute("""
                    SELECT schemaname, tablename 
                    FROM pg_tables 
                    WHERE schemaname NOT IN ('information_schema', 'pg_catalog')
                    ORDER BY schemaname, tablename;
                """)
                tables = cursor.fetchall()

            for schema, table in tables:
                try:
                    start_time = time.time()
                    with connection.cursor() as cursor:
                        # ä½¿ç”¨éé˜»å¡çš„VACUUM
                        cursor.execute(f'VACUUM (ANALYZE, VERBOSE) "{schema}"."{table}";')
                    
                    execution_time = time.time() - start_time
                    self.stdout.write(
                        self.style.SUCCESS(
                            f"âœ… VACUUM ANALYZE {schema}.{table} completed in {execution_time:.2f}s"
                        )
                    )
                except Exception as e:
                    self.stdout.write(
                        self.style.ERROR(f"âŒ VACUUM ANALYZE {schema}.{table} failed: {e}")
                    )

        except Exception as e:
            self.stdout.write(
                self.style.ERROR(f"âŒ Failed to get table list: {e}")
            )

    def generate_optimization_report(self):
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        self.stdout.write(
            self.style.SUCCESS('\nğŸ“Š Database Optimization Report')
        )
        self.stdout.write('=' * 50)
        
        # è¿æ¥é…ç½®
        self.stdout.write(f"ğŸ”— Connection Max Age: {getattr(settings, 'DATABASES', {}).get('default', {}).get('CONN_MAX_AGE', 'Not set')}")
        self.stdout.write(f"ğŸ”’ Atomic Requests: {getattr(settings, 'DATABASES', {}).get('default', {}).get('ATOMIC_REQUESTS', 'Not set')}")
        
        # ç¼“å­˜é…ç½®
        cache_backend = getattr(settings, 'CACHES', {}).get('default', {}).get('BACKEND', 'Not configured')
        self.stdout.write(f"ğŸ’¾ Cache Backend: {cache_backend}")
        
        # ç´¢å¼•ç»Ÿè®¡
        total_indexes = (
            len(INDEX_OPTIMIZATION_CONFIG['HIGH_FREQUENCY_INDEXES']) +
            len(INDEX_OPTIMIZATION_CONFIG['COMPOSITE_INDEXES']) +
            len(INDEX_OPTIMIZATION_CONFIG['PARTIAL_INDEXES'])
        )
        self.stdout.write(f"ğŸ“ˆ Optimized Indexes: {total_indexes}")
        
        self.stdout.write('=' * 50)